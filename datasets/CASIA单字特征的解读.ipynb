{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单字特征的解读\n",
    "\n",
    "本教程讨论 HWDB1.0\\~1.1 以及 OLHWDB1.0\\~1.1，下载到个人电脑目录下,你可以根据自己的实际目录来调整设置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:06:47.370753Z",
     "start_time": "2023-06-04T14:06:47.357402Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:08:20.816756Z",
     "start_time": "2023-06-04T14:08:20.814786Z"
    }
   },
   "outputs": [],
   "source": [
    "# del sys.path['']\n",
    "del sys.path[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:08:22.495246Z",
     "start_time": "2023-06-04T14:08:22.482365Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:08:30.173740Z",
     "start_time": "2023-06-04T14:08:30.165135Z"
    }
   },
   "outputs": [],
   "source": [
    "# CASIA 数据集所在根目录\n",
    "root = './datas_zips/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入本教程需要使用的包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# ERROR:: Could not find a local HDF5 installation.\n",
    "#          You may need to explicitly state where your local HDF5 headers and\n",
    "#          library can be found by setting the ``HDF5_DIR`` environment\n",
    "#          variable or by using the ``--hdf5`` command-line option.\n",
    "\n",
    "# 我的 Mac 上会出现这个问题，在安装 tables 的时候\n",
    "\n",
    "# 找到了一个 sof 上的解决方案。\n",
    "\n",
    "# https://stackoverflow.com/questions/73029883/could-not-find-hdf5-installation-for-pytables-on-m1-mac\n",
    "\n",
    "!pip install cython\n",
    "!brew install hdf5\n",
    "!brew install c-blosc\n",
    "!export HDF5_DIR=/opt/homebrew/opt/hdf5\n",
    "!export BLOSC_DIR=/opt/homebrew/opt/c-blosc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 安装下面的 tables，首先需要在本地安装 hdf5，在 mac 上的安装方式为 brew install hdf5\n",
    "!pip install tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1iXIrJ](https://oss.images.shujudaka.com/uPic/1iXIrJ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:08:39.373987Z",
     "start_time": "2023-06-04T14:08:39.367654Z"
    }
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:08:40.974624Z",
     "start_time": "2023-06-04T14:08:40.967799Z"
    }
   },
   "outputs": [],
   "source": [
    "import tables as tb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Path` 更加友好的管理文件的路径："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:08:43.882470Z",
     "start_time": "2023-06-04T14:08:43.868923Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root = Path(root)\n",
    "# 查看 root 的全部文件\n",
    "zips = []\n",
    "for pname in root.iterdir():\n",
    "    for name in Path(pname).iterdir():\n",
    "        zips.append(name.parts[-1])\n",
    "\n",
    "zips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个单字的特征均以 `.mpf` 形式保存手工特征，可以看出上述文件均为压缩包，下面使用 `zipfile` 对压缩文件进行解读："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:08:51.034636Z",
     "start_time": "2023-06-04T14:08:51.020047Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = ZipFile(list(root.glob('**/HWDB1.0trn.zip'))[0])\n",
    "z.namelist()[1:5] # 查看前4个人写的 MPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:08:52.258516Z",
     "start_time": "2023-06-04T14:08:52.243748Z"
    }
   },
   "outputs": [],
   "source": [
    "len(z.namelist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:08:53.274022Z",
     "start_time": "2023-06-04T14:08:53.252160Z"
    }
   },
   "outputs": [],
   "source": [
    "z.namelist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入 MPF 的解码器：MPFDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:09:06.567393Z",
     "start_time": "2023-06-04T14:09:06.562747Z"
    }
   },
   "outputs": [],
   "source": [
    "from casia.feature import MPFDecoder, zipfile2bunch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将 MPF 转换为 bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:09:10.425150Z",
     "start_time": "2023-06-04T14:09:10.411024Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zip_name = list(root.glob('**/HWDB1.0trn.zip'))[0]\n",
    "zip_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:09:29.086951Z",
     "start_time": "2023-06-04T14:09:21.752064Z"
    }
   },
   "outputs": [],
   "source": [
    "mb = zipfile2bunch(zip_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T13:59:03.887371Z",
     "start_time": "2023-06-04T13:59:03.254986Z"
    }
   },
   "outputs": [],
   "source": [
    "# 将数据集进行输出\n",
    "for key,value in mb.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:09:36.383862Z",
     "start_time": "2023-06-04T14:09:36.360965Z"
    }
   },
   "outputs": [],
   "source": [
    "# 查看图片\n",
    "mb['HWDB1.0trn/001.mpf']['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:09:39.578094Z",
     "start_time": "2023-06-04T14:09:39.568410Z"
    }
   },
   "outputs": [],
   "source": [
    "# 寻求它的类型\n",
    "type(mb['HWDB1.0trn/001.mpf']['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T13:59:23.431371Z",
     "start_time": "2023-06-04T13:59:23.394228Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = mb['HWDB1.0trn/001.mpf']['dataset']\n",
    "df.iloc[0, :].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将 bunch 转换为 JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要安装\n",
    "\n",
    "```\n",
    "pip3 install torch torchvision torchaudio\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:12:17.402357Z",
     "start_time": "2023-06-04T14:12:17.393733Z"
    }
   },
   "outputs": [],
   "source": [
    "from loader.utils.dataset import bunch2json,json2bunch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:12:26.131604Z",
     "start_time": "2023-06-04T14:12:26.124771Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path('data')\n",
    "if not data_dir.exists(): # 如果不存在\n",
    "    data_dir.mkdir() # 创建目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:12:40.850385Z",
     "start_time": "2023-06-04T14:12:39.908634Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "json_path = 'data/features.json'\n",
    "bunch2json(mb, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:13:23.980978Z",
     "start_time": "2023-06-04T14:13:23.355826Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 再次载入数据\n",
    "mpf_bunch = json2bunch(json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将 bunch 转换为 HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:13:45.079197Z",
     "start_time": "2023-06-04T14:13:45.067990Z"
    }
   },
   "outputs": [],
   "source": [
    "def bunch2hdf(bunch, save_path):\n",
    "    '''将 bunch 转换为 HDF5'''\n",
    "    filters = tb.Filters(complevel=7, shuffle=False)  # 过滤信息，用于压缩文件\n",
    "    h = tb.open_file(save_path, 'w', filters=filters, title='Xinet\\'s dataset')\n",
    "    for name in bunch:  # 生成数据集\"头\"\n",
    "        _name = name.replace('/', '__')\n",
    "        _name = _name.replace('.', '_')\n",
    "        h.create_group('/', name=_name, filters=filters)\n",
    "        h.create_array(f\"/{_name}\", 'text',\n",
    "                       bunch[name]['text'].encode())\n",
    "        features = bunch[name]['dataset']\n",
    "        h.create_array(f\"/{_name}\", 'labels',\n",
    "                       \" \".join([l for l in features.index]).encode())\n",
    "        h.create_array(f\"/{_name}\", 'features', features.values)\n",
    "    h.close()  # 防止资源泄露"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:13:49.159244Z",
     "start_time": "2023-06-04T14:13:48.027375Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "hdf_path = 'data/features.h5'\n",
    "bunch2hdf(mpf_bunch, hdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:13:57.284149Z",
     "start_time": "2023-06-04T14:13:57.273179Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "h5 = tb.open_file(hdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:14:03.212140Z",
     "start_time": "2023-06-04T14:14:03.198969Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取某个 mpf 的特征矩阵的 shape\n",
    "h5.root.HWDB1_0trn__001_mpf.features[:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:14:09.426232Z",
     "start_time": "2023-06-04T14:14:09.408680Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取某个 mpf 的特征介绍\n",
    "h5.root.HWDB1_0trn__001_mpf.text.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:14:18.955998Z",
     "start_time": "2023-06-04T14:14:18.940929Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取某个 mpf 的标签信息\n",
    "labels = h5.root.HWDB1_0trn__001_mpf.labels.read().decode()\n",
    "labels = np.array(labels.split(' '))\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试 JSON 与 HDF5 的文件大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:14:27.011374Z",
     "start_time": "2023-06-04T14:14:27.000712Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sys import getsizeof\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"JSON Python 对象占用空间大小为 {getsizeof(mpf_bunch)/1e3} kB, 文件大小为 {os.path.getsize(json_path)/1e9} G\")\n",
    "print(\n",
    "    f\"HDF5 Python 对象占用空间大小为 {getsizeof(h5)} B, 文件大小为 {os.path.getsize(hdf_path)/1e9} G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:14:36.298250Z",
     "start_time": "2023-06-04T14:14:36.276567Z"
    }
   },
   "outputs": [],
   "source": [
    "h5.close()  # 关闭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 打包多个 zip 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:28:16.995506Z",
     "start_time": "2023-06-04T14:28:16.983312Z"
    }
   },
   "outputs": [],
   "source": [
    "root2 = Path(\"./datas_zips/Character_Sample_Data/\")\n",
    "zip_gnt_names = set(root2.glob('*Gnt*.zip')) # GNT 名称列表\n",
    "zip_pot_names = set(root2.glob('*Pot*.zip')) # POT名称列表\n",
    "\n",
    "# 查看 root 的全部文件\n",
    "alls = []\n",
    "for pname in root.iterdir():\n",
    "    for name in Path(pname).iterdir():\n",
    "        alls.append(name)\n",
    "alls = set(alls)\n",
    "alls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:28:21.241781Z",
     "start_time": "2023-06-04T14:28:21.233037Z"
    }
   },
   "outputs": [],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:28:22.161379Z",
     "start_time": "2023-06-04T14:28:22.152645Z"
    }
   },
   "outputs": [],
   "source": [
    "zip_gnt_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:28:23.016804Z",
     "start_time": "2023-06-04T14:28:23.009122Z"
    }
   },
   "outputs": [],
   "source": [
    "zip_pot_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:28:24.316680Z",
     "start_time": "2023-06-04T14:28:24.313503Z"
    }
   },
   "outputs": [],
   "source": [
    "# MPF 名称列表\n",
    "zip_mpf_names = alls - zip_pot_names - zip_gnt_names\n",
    "zip_mpf_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:29:11.661135Z",
     "start_time": "2023-06-04T14:28:42.126046Z"
    }
   },
   "outputs": [],
   "source": [
    "mpf_bunch = {}\n",
    "for mpf_name in zip_mpf_names:\n",
    "    mpf_bunch.update(zipfile2bunch(mpf_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存为 JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:30:41.941597Z",
     "start_time": "2023-06-04T14:30:37.784523Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "json_path = 'data/features.json'\n",
    "bunch2json(mpf_bunch, json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存为 HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:30:50.403891Z",
     "start_time": "2023-06-04T14:30:45.201551Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "hdf_path = 'data/features.h5'\n",
    "bunch2hdf(mpf_bunch, hdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入 JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:30:56.418926Z",
     "start_time": "2023-06-04T14:30:53.222756Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "mpf_bunch = json2bunch(json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入 HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T02:08:41.591554Z",
     "start_time": "2023-06-05T02:08:41.504494Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "h5 = tb.open_file(hdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 再次测试文件大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T02:09:00.158877Z",
     "start_time": "2023-06-05T02:09:00.149775Z"
    }
   },
   "outputs": [],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"JSON Python 对象占用空间大小为 {getsizeof(mpf_bunch)/1e3} kB, 文件大小为 {Path(json_path).stat().st_size/1e9} G\")\n",
    "print(\n",
    "    f\"HDF5 Python 对象占用空间大小为 {getsizeof(h5)} B, 文件大小为 {Path(hdf_path).stat().st_size/1e9} G\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上述的展示可以看出 HDF5 优于 JSON 与 ZipFile，所以下面仅仅考虑 HDF5 文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解析 features.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T02:48:07.181345Z",
     "start_time": "2023-06-05T02:48:07.170505Z"
    }
   },
   "outputs": [],
   "source": [
    "h5.get_filesize() # 获取文件大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T02:48:16.854300Z",
     "start_time": "2023-06-05T02:48:16.712104Z"
    }
   },
   "outputs": [],
   "source": [
    "nodes = h5.list_nodes('/')  # 列出所有 MPF 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T02:48:20.461510Z",
     "start_time": "2023-06-05T02:48:20.452111Z"
    }
   },
   "outputs": [],
   "source": [
    "nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T02:48:52.034754Z",
     "start_time": "2023-06-05T02:48:52.026860Z"
    }
   },
   "outputs": [],
   "source": [
    "len(nodes)  # 统计 MPF 个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T02:48:59.662706Z",
     "start_time": "2023-06-05T02:48:59.656399Z"
    }
   },
   "outputs": [],
   "source": [
    "data_iter = h5.iter_nodes('/') # 所有 MPF 数据以迭代器的方式使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T02:49:03.526361Z",
     "start_time": "2023-06-05T02:49:03.515545Z"
    }
   },
   "outputs": [],
   "source": [
    "next(data_iter) # 取出一个 MPF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取 MPF 的特征矩阵与标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T02:49:26.366005Z",
     "start_time": "2023-06-05T02:49:26.354804Z"
    }
   },
   "outputs": [],
   "source": [
    "mpf_name = 'HWDB1_0trn__007_mpf'\n",
    "# 依据 MPF 的名称获取 MPF\n",
    "mpf = h5.get_node('/', mpf_name)\n",
    "mpf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T02:49:51.679979Z",
     "start_time": "2023-06-05T02:49:51.665623Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_features(mpf):\n",
    "    '''获取 MPF 的特征矩阵'''\n",
    "    return mpf.features[:]\n",
    "\n",
    "\n",
    "def get_labels(mpf):\n",
    "    '''获取 MPF 的标签数组'''\n",
    "    labels_str = mpf.labels.read().decode()\n",
    "    return np.array(labels_str.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T02:49:58.624180Z",
     "start_time": "2023-06-05T02:49:58.597029Z"
    }
   },
   "outputs": [],
   "source": [
    "features = get_features(mpf)  # 获取特征矩阵\n",
    "labels = get_labels(mpf)      # 获取标签\n",
    "h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T02:50:19.388087Z",
     "start_time": "2023-06-05T02:50:19.377270Z"
    }
   },
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T02:50:24.807324Z",
     "start_time": "2023-06-05T02:50:24.800007Z"
    }
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPF 迭代器\n",
    "\n",
    "依据特征矩阵与标签函数，定义了 MPF 迭代器，获取方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T02:51:33.940637Z",
     "start_time": "2023-06-05T02:51:33.924354Z"
    }
   },
   "outputs": [],
   "source": [
    "class CASIAFeature:\n",
    "    def __init__(self, hdf_path):\n",
    "        '''casia 数据 MPF 特征处理工具'''\n",
    "        self.h5 = tb.open_file(hdf_path)\n",
    "\n",
    "    def _features(self, mpf):\n",
    "        '''获取 MPF 的特征矩阵'''\n",
    "        return mpf.features[:]\n",
    "\n",
    "    def _labels(self, mpf):\n",
    "        '''获取 MPF 的标签数组'''\n",
    "        labels_str = mpf.labels.read().decode()\n",
    "        return np.array(labels_str.split(' '))\n",
    "\n",
    "    def __iter__(self):\n",
    "        '''返回 (features, labels)'''\n",
    "        for mpf in self.h5.iter_nodes('/'):\n",
    "            yield self._features(mpf), self._labels(mpf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPF 迭代器的使用方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T02:51:41.882297Z",
     "start_time": "2023-06-05T02:51:41.860086Z"
    }
   },
   "outputs": [],
   "source": [
    "mpf_iter = CASIAFeature(hdf_path)\n",
    "# 以迭代器的方式获取数据\n",
    "for features, labels in mpf_iter:\n",
    "    print(features.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-04T14:32:30.651803Z",
     "start_time": "2023-06-04T14:32:30.065088Z"
    }
   },
   "outputs": [],
   "source": [
    "h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为了将 CASIA 划分为训练集与测试集，需要重新打包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重启 Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T06:23:55.818901Z",
     "start_time": "2023-06-05T06:23:55.810311Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd()+\"/loader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T06:23:56.598537Z",
     "start_time": "2023-06-05T06:23:56.582920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lincolnmac16/Documents/GitHub/crnn-pytorch/datasets',\n",
       " '/Users/lincolnmac16/Documents/GitHub/crnn-pytorch',\n",
       " '/Users/lincolnmac16/opt/anaconda3/envs/crnn-pytorch/lib/python310.zip',\n",
       " '/Users/lincolnmac16/opt/anaconda3/envs/crnn-pytorch/lib/python3.10',\n",
       " '/Users/lincolnmac16/opt/anaconda3/envs/crnn-pytorch/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/Users/lincolnmac16/opt/anaconda3/envs/crnn-pytorch/lib/python3.10/site-packages',\n",
       " '/Users/lincolnmac16/Documents/GitHub/crnn-pytorch/datasets/loader']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T06:23:57.672531Z",
     "start_time": "2023-06-05T06:23:57.446963Z"
    }
   },
   "outputs": [],
   "source": [
    "from casia.feature import CASIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fLtgb9](https://oss.images.shujudaka.com/uPic/fLtgb9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T06:24:36.082205Z",
     "start_time": "2023-06-05T06:23:59.558173Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train names->\n",
      "{PosixPath('datas_zips/Feature_Data/HWDB1.1trn.zip'), PosixPath('datas_zips/Feature_Data/OLHWDB1.0trn.zip'), PosixPath('datas_zips/Feature_Data/OLHWDB1.1trn.zip'), PosixPath('datas_zips/Feature_Data/HWDB1.0trn.zip')}\n",
      "Test  names->\n",
      "{PosixPath('datas_zips/Feature_Data/OLHWDB1.1tst.zip'), PosixPath('datas_zips/Feature_Data/HWDB1.0tst.zip'), PosixPath('datas_zips/Feature_Data/OLHWDB1.0tst.zip'), PosixPath('datas_zips/Feature_Data/HWDB1.1tst.zip')}\n"
     ]
    }
   ],
   "source": [
    "# CASIA 数据集所在根目录\n",
    "root = 'datas_zips/'\n",
    "save_path = 'data/features.h5'\n",
    "\n",
    "self = CASIA(root)  # 该类实现数据集的划分\n",
    "self.bunch2hdf(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T06:24:42.416923Z",
     "start_time": "2023-06-05T06:24:42.407451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.59 ms, sys: 1.16 ms, total: 2.75 ms\n",
      "Wall time: 2.66 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 载入 HDF5\n",
    "import tables as tb\n",
    "h5 = tb.open_file(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T06:24:45.106184Z",
     "start_time": "2023-06-05T06:24:45.091571Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/ (RootGroup) \"Xinet's casia dataset\"\n",
       "  children := ['test' (Group), 'train' (Group)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-05T06:24:50.375018Z",
     "start_time": "2023-06-05T06:24:50.354742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3726, 512) (3726,)\n"
     ]
    }
   ],
   "source": [
    "from casia.feature import CASIAFeature\n",
    "mpf_dataset = CASIAFeature(save_path)\n",
    "# 以测试集的迭代器的方式获取数据\n",
    "for features, labels in mpf_dataset.test_iter():\n",
    "    print(features.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
